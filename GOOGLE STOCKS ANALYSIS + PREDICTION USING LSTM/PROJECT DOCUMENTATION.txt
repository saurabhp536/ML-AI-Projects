### Stock Price Forecasting Project

#### Project Overview
This project involves predicting stock prices using historical data. It explores two different machine learning approaches:

1. **Linear Regression**: A simple and interpretable method for forecasting.
2. **LSTM (Long Short-Term Memory)**: A neural network model designed for time-series data.

#### Dataset Details
- **File Name**: `Data.csv`
- **Columns**:
  - `Date`: The trading date.
  - `Adj Close`: Adjusted closing price.
  - `Close`: Closing price.
  - `High`: Highest price of the day.
  - `Low`: Lowest price of the day.
  - `Open`: Opening price.
  - `Volume`: Trading volume.
- **Size**: 233 rows and 7 columns.

#### Objectives
1. Preprocess the data for machine learning models.
2. Implement and compare performance of Linear Regression and LSTM models.
3. Visualize predictions to evaluate model effectiveness.

#### Tools & Libraries
- **Python Libraries**: pandas, numpy, matplotlib, scikit-learn, tensorflow/keras.
- **Machine Learning Models**:
  - Linear Regression from scikit-learn.
  - LSTM from TensorFlow/Keras.

#### Steps Implemented

1. **Data Preprocessing**:
   - Skipped the first row as it contained metadata instead of stock prices.
   - Converted date to datetime format and other columns to numeric types.
   - Removed rows with missing or invalid values.

2. **Linear Regression**:
   - Used the `Adj Close` price to predict the next day’s price.
   - Split the data into training and testing sets (80%-20%).
   - Trained a Linear Regression model.
   - Evaluated the model using RMSE (Root Mean Square Error).

3. **LSTM Model**:
   - Scaled the `Adj Close` values to the range [0, 1] using Min-Max Scaling.
   - Created sequences of past 10 days’ data to predict the next day’s price.
   - Defined a two-layer LSTM model with a Dense output layer.
   - Compiled the model with Adam optimizer and mean squared error loss.
   - Trained the model for 20 epochs with a batch size of 32.
   - Rescaled predictions back to original price values.

4. **Visualization**:
   - Plotted actual vs predicted prices to assess model performance.

#### Results

- **Linear Regression**:
  - RMSE: ~2.61
  - Predictions were reasonably close to actual values but lacked the ability to capture temporal trends.

- **LSTM**:
  - Provided better modeling of time-series patterns.
  - Predicted prices followed the trend of actual prices more closely.

#### Code Snippets

1. **Data Cleaning**:
```python
# Load the data
import pandas as pd

data = pd.read_csv('Data.csv', skiprows=1)
data.columns = ['Date', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']
data['Date'] = pd.to_datetime(data['Date'])
data[['Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']] = \
    data[['Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']].apply(pd.to_numeric, errors='coerce')
data = data.dropna()
```

2. **Linear Regression**:
```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# Prepare data
X = data[['Adj Close']]
y = data['Adj Close'].shift(-1).dropna()
X = X.iloc[:-1]  # Match size with y

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)
rmse = mean_squared_error(y_test, y_pred, squared=False)
```

3. **LSTM**:
```python
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import numpy as np

# Scale data
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data[['Adj Close']])

# Create sequences
sequence_length = 10
X_lstm, y_lstm = [], []
for i in range(sequence_length, len(scaled_data)):
    X_lstm.append(scaled_data[i-sequence_length:i, 0])
    y_lstm.append(scaled_data[i, 0])

X_lstm, y_lstm = np.array(X_lstm), np.array(y_lstm)
X_train, X_test = X_lstm[:int(len(X_lstm)*0.8)], X_lstm[int(len(X_lstm)*0.8):]
y_train, y_test = y_lstm[:int(len(y_lstm)*0.8)], y_lstm[int(len(y_lstm)*0.8):]

# Define LSTM model
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    LSTM(50, return_sequences=False),
    Dense(25),
    Dense(1)
])

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=20, batch_size=32)

# Predictions
predictions = scaler.inverse_transform(model.predict(X_test))
```

#### Conclusion
The project demonstrates the effectiveness of machine learning models in forecasting stock prices. While Linear Regression is simple and interpretable, LSTM captures time-series patterns more effectively, making it suitable for stock price prediction.

